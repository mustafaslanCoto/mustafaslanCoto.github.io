{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "200f87ae",
   "metadata": {},
   "source": [
    "## The difference between on-policy and off-policy {.smaller}\n",
    "\n",
    "### On-Policy Learning\n",
    "\n",
    "Learns about the policy it is currently using to make decisions.\n",
    "\n",
    "The same policy is used for both:\n",
    "\n",
    "-   Acting (exploring the environment)\n",
    "\n",
    "-   Learning (updating value functions)\n",
    "\n",
    "Example: SARSA\n",
    "\n",
    "-   Updates Q-values using the action that was actually taken.\n",
    "\n",
    "-   Learns the value of the $\\varepsilon$-greedy policy it follows.\n",
    "\n",
    "### Off-Policy Learning\n",
    "\n",
    "Learns about one policy while following another.\n",
    "\n",
    "Uses:\n",
    "\n",
    "-   A behavior policy for exploration (e.g., $\\varepsilon$-greedy)\n",
    "\n",
    "-   A target policy for learning (e.g., greedy)\n",
    "\n",
    "Example: Q-learning\n",
    "\n",
    "-   Even if the agent explores randomly, it updates Q-values based on the best possible action (max over Q), as if it was following a greedy policy.\n",
    "\n",
    "## Example: {.smaller}\n",
    "\n",
    "ðŸŽ¯ Imagine you're learning to play chess.\n",
    "\n",
    "ðŸ§‘ On-policy (SARSA-like):\n",
    "\n",
    "-   Youâ€™re learning by watching yourself play, including your mistakes and explorations.\n",
    "-   You play games using a mix of good and random moves (e.g., trying new strategies).\n",
    "-   You update your knowledge based on what you actually did in each game.\n",
    "-   You get better at playing the way you currently play, gradually improving it.\n",
    "\n",
    "âœ… On-policy:\n",
    "\n",
    "You learn the value of the policy you're following.\n",
    "\n",
    "ðŸ‘€ Off-policy (Q-learning-like):\n",
    "\n",
    "-   Youâ€™re learning how a grandmaster would play, while still playing your own games.\n",
    "-   You still explore (e.g., try risky moves), but...\n",
    "-   When updating your knowledge, you ask what the best move would have been, not the one you actually chose.\n",
    "-   You get better at playing like the grandmaster, even though you're not playing like them yet.\n",
    "\n",
    "âœ… This is off-policy:\n",
    "\n",
    "You learn the value of a different, better policy (often greedy), while following a more exploratory one.\n",
    "\n",
    "## Notes\n",
    "\n",
    "-   **Reinforcement learning** is a framework for learning how to interact with environment from experience.\n",
    "-   Agent takes actions to interact with environment\n",
    "-   The big challange in RL Design a policy of what actions to take given a state s to maximize a future reward\n",
    "-   Q(s,a) tells us what is the quality of being in state s and taking action a. Then once I find myself in a state s, I just have to look across all of the actions and pick the one that gives the best quality. If I do that in future I will maximize my value."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
