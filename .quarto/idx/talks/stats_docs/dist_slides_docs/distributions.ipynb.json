{"title":"Random Variables","markdown":{"yaml":{"title":"Random Variables","author":[{"name":"Mustafa Aslan","title":"PhD Student","affiliation":"Cardiff University, UK","email":"aslanm@cardiff.ac.uk"}],"description":"A quick notebook on distributions in statistics and machine learning.","date":"2025-04-23","categories":["talks"],"format":"html"},"headingText":"1. Discrete Random Variables","containsRefs":false,"markdown":"\n\n\nFor a discrete random variable $X$, we define the probability mass function $p(\\alpha)$ of $X$ by\n\n$$\np(\\alpha) = P(X = \\alpha)\n$$\n\nThe probability mass function $p(\\alpha)$ is positive for at most a countable number of values of $a$. That is, if $X$ must assume one of the values $x_1, x_2,\\dots ,$ then\n\n$$\np(x_i) \\geq 0 \\text{ for } i = 1, 2, \\dots\n$$\n\nand\n\n$$\n\\sum_{i=1}^{\\infty} p(x_i) = 1\n$$\n\nThe cumulative distribution function $F(x)$ can be expressed in terms of $p(\\alpha)$ by\n\n$$\nF(\\alpha) = P(X \\leq \\alpha) = \\sum_{x_i \\leq \\alpha} p(x_i)\n$$\n\n### Expectation of a Random Variable in Discrete Case\n\nIf $X$ is a discrete random variable having a probability mass function $p(x)$, then the expected value of $X$ is defined by\n\n$$\nE(X) = \\sum_{x_i} x_i p(x_i)\n$$\n\n\n\n\n## 1.1 Bernoulli Random Variable\n\nA Bernoulli random variable is a discrete random variable that takes the value 1 with probability $p$ and the value 0 with probability $1-p$. The probability mass function of a Bernoulli random variable $X$ is given by\n$$\np(x) = \\begin{cases}\n1-p & \\text{if } x = 0 \\\\\np & \\text{if } x = 1\n\\end{cases}\n$$\n\nThe expected value of a Bernoulli random variable is given by\n$$\nE(X) = 0 \\cdot (1-p) + 1 \\cdot p = p\n$$\n\nThe variance of a Bernoulli random variable is given by\n$$\nVar(X) = E(X^2) - (E(X))^2 = p - p^2 = p(1-p)\n$$\n\n## 1.2 Binomial Random Variable\n\nSuppose that $n$ independent trials, each of which results in a “success” with probability $p$ and in a “failure” with probability $1−p$, are to be performed. If $X$ represents the number of successes that occur in the $n$ trials, then $X$ is said to be a binomial random variable with parameters $n, p$. The probability mass function of a binomial random variable having parameters\n$(n, p)$ is given by\n\n$$\np(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n\n$$\n\nwhere $\\binom{n}{x} = \\frac{n!}{x!(n-x)!}$ is the binomial coefficient, which counts the number of ways to choose $x$ successes from $n$ trials.\n\n### Expectation of a Binomial Random Variable\n\nIf $X$ is a binomial random variable with parameters $n$ and $p$, then the expected value of $X$ is given by\n$$\nE(X) = np\n$$\n### Variance of a Binomial Random Variable\nIf $X$ is a binomial random variable with parameters $n$ and $p$, then the variance of $X$ is given by\n$$\nVar(X) = np(1-p)\n$$\n    \n\n## The Poisson Random Variable\n\nA random variable $X$ taking on one of the values $0, 1, 2, \\dots,$ is said to be a Poisson random variable with parameter $\\lambda$, if for some $\\lambda > 0$,\n\n$$\np(i) = P \\{ X = i \\} = e^{-\\lambda} \\frac{\\lambda^i}{i!}, \\quad i = 0, 1, \\ldots\n$$\n\n### Expectation of a Poisson Random Variable\n\nIf $X$ is a Poisson random variable with parameter $\\lambda$, then the expected value of $X$ is given by\n\n$$\nE(X) = \\sum_{i=0}^{\\infty} i e^{-\\lambda} \\frac{\\lambda^i}{i!}\n= e^{-\\lambda} \\sum_{i=1}^{\\infty} \\frac{\\lambda^i}{(i-1)!}\n= e^{-\\lambda} \\lambda \\sum_{i=0}^{\\infty} \\frac{\\lambda^i}{i!}\n= e^{-\\lambda} \\lambda e^{\\lambda}\n= \\lambda\n$$\n\nwhere we have used the identity $\\sum_{i=0}^{\\infty} \\frac{\\lambda^i}{i!} = e^{\\lambda}$.\n\n# 2. Continuous Random Variables\nThe function $f(x)$ is called the *probability density function* of the random variable $X$.\n$$\nP \\{X \\in B \\} = \\int_B f(x) dx \\tag{1}\n$$\n\nThe probability that $X$ will be in $B$ may be obtained by integrating the probability density function over the set $B$.\n\n$$\nP\\{X \\in (-\\infty, \\infty)\\} = \\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\n$$\n\n\nAll probability statements about $X$ can be answered in terms of $f(x)$. For instance, letting $B = [a, b]$, we obtain\n\n$$\nP\\{a \\leq X \\leq b \\} = \\int_a^b f(x) \\, dx \\tag{2}\n$$\n\nThe relationship between the cumulative distribution $F(\\cdot)$ and the probability density $f(\\cdot)$ is expressed by\n\n$$\nF(\\alpha) = P\\{X \\in (-\\infty, \\alpha]\\} = \\int_{-\\infty}^{\\alpha} f(x) \\, dx\n$$\n\nDifferentiating both sides of the preceding yields\n$$\n\\frac{d}{d\\alpha} F(\\alpha) = f(\\alpha)\n$$\n\nThat is, the density is the derivative of the cumulative distribution function. A somewhat more intuitive interpretation of the density function may be obtained from Equation (2) as\n\n$$\nP\\{\\alpha-\\frac{\\epsilon}{2} \\leq X \\leq \\alpha+\\frac{\\epsilon}{2} \\} = \\int_{\\alpha-\\frac{\\epsilon}{2}}^{a+\\frac{\\epsilon}{2}} f(x) \\, dx  \\approx \\epsilon f(x)\n$$\n\nwhen $\\epsilon$ is small. In other words, the probability that $X$ will be contained in an interval of length $\\epsilon$ around the point $\\alpha$ is approximately $\\epsilon f(a)$.\n\n\n### Expectation of a Random Variable in Continuous Case\nIf $X$ is a continuous random variable having a probability density function $f(x)$, then the expected value of $X$ is defined by\n$$\nE(X) = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n$$\n\n## 2.1 Exponential Random Variables\nA continuous random variable whose probability density function is given, for\nsome $\\lambda > 0$, by:\n$$\nf(x) = \\begin{cases}\n\\lambda e^{-\\lambda x} & x \\geq 0 \\\\\n0 & x < 0\n\\end{cases}\n$$\n\nis said to be an exponential random variable with parameter $\\lambda$, which is the mean of the distribution. The cumulative distribution function is given by\n\n$$\nF(\\alpha) =  \\int_0^\\alpha \\lambda e^{-\\lambda x} \\, dx, = 1-e^{-\\lambda \\alpha}  \\quad \\alpha \\geq 0\n$$\n\nNote that $F(\\infty) = \\int_0^\\infty \\lambda e^{-\\lambda x} \\, dx = 1$.\n\n### Expectation of an Exponential Random Variable\nIf $X$ is an exponential random variable with parameter $\\lambda$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_0^\\infty x \\lambda e^{-\\lambda x} \\, dx\n$$\n\nIntegration by parts ($dv = \\lambda e^{-\\lambda x}, u = x$) yields\n$$\nE(X) = \\left[ -\\frac{x}{\\lambda} e^{-\\lambda x} \\right]_0^\\infty + \\frac{1}{\\lambda} \\int_0^\\infty e^{-\\lambda x} \\, dx\n= 0 + \\frac{1}{\\lambda} \\cdot \\frac{1}{\\lambda} = \\frac{1}{\\lambda}\n$$\n\n\n## 2.2 Gamma Random Variables\n\nA continuous random variable whose density is given by:\n$$\nf(x) = \\begin{cases}\n\\frac{\\lambda e^{- \\lambda x} {(\\lambda x)}^{\\alpha-1}}{\\Gamma (\\alpha)} & x \\geq 0 \\\\\n0 & x < 0\n\\end{cases}\n$$\n\nfor some $\\lambda>0$ and $\\alpha>0$ is said to be a gamma random variable with parameters\n$\\alpha, \\lambda$. \n\nThe quantity $\\Gamma (\\alpha)$ is called the gamma function and is defined by\n\n$$\n\\Gamma (\\alpha) = \\int_0^\\infty e^{-x} x^{\\alpha-1} \\, dx = (\\alpha-1)!\n$$\n\n### Expectation of a Gamma Random Variable\nIf $X$ is a gamma random variable with parameters $\\alpha$ and $\\lambda$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_0^\\infty x \\frac{\\lambda e^{- \\lambda x} {(\\lambda x)}^{\\alpha-1}}{\\Gamma (\\alpha)} \\, dx\n= \\frac{1}{\\lambda} \\int_0^\\infty e^{-x} x^{\\alpha} \\, dx\n= \\frac{1}{\\lambda} \\cdot \\Gamma (\\alpha + 1)\n= \\frac{1}{\\lambda} \\cdot \\alpha \\Gamma (\\alpha)\n= \\frac{\\alpha}{\\lambda}\n$$\n\n\n## 2.3 Normal Random Variables\n\nWe say that $X$ is a normal random variable (or simply that $X$ is normally distributed) with parameters $\\mu$ and $\\sigma ^2$ if the density of X is given by\n\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\quad -\\infty < x < \\infty\n$$\n\nThis density function is a bell-shaped curve that is symmetric around $\\mu$.\n\nThe mean of the normal distribution is $\\mu$ and the variance is $\\sigma^2$. The cumulative distribution function is given by\n\n$$\nF_X(\\alpha) = P(X \\leq \\alpha) = \\int_{-\\infty}^ \\alpha \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n$$\n\n### Expectation of a Normal Random Variable\nIf $X$ is a normal random variable with parameters $\\mu$ and $\\sigma^2$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_{-\\infty}^\\infty x \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n= \\mu \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n= \\mu \\cdot 1\n= \\mu\n$$\n\n\n\n\n## Expectation of a Function of a Random Variable\n\n### In Discrete Case\nIf $X$ is a discrete random variable having a probability mass function $p(x)$, and $g(x)$ is a function of $x$, then the expected value of $g(X)$ is defined by\n$$\nE(g(X)) = \\sum_{x_i} g(x_i) p(x_i)\n$$\n### In Continuous Case\nIf $X$ is a continuous random variable having a probability density function $f(x)$, and $g(x)$ is a function of $x$, then the expected value of $g(X)$ is defined by\n$$\nE(g(X)) = \\int_{-\\infty}^{\\infty} g(x) f(x) \\, dx\n$$\n\n# Jointly Distributed Random Variables\n\nWe are often interested in probability statements concerning two or more random variables. To deal with such probabilities, we define, for any two random variables $X$ and $Y$, the joint cumulative probability distribution function of $X$ and $Y$ by\n\n$$\nF(a,b) = P(X \\leq a, Y \\leq b), \\quad -\\infty < a,b < \\infty\n$$\n\nThe cumulative distribution of $X$ can be obtained from the joint distribution of $X$ and $Y$ as follows:\n\n$$\n\\begin{align*}\nF_X(a) &= P(X \\leq a) \\\\\n& = P(X \\leq a, Y \\leq \\infty) \\\\\n& = F(a, \\infty) \\\\\n\\end{align*}\n$$\n\nSimilarly, the cumulative distribution of $Y$ can be obtained from the joint distribution of $X$ and $Y$ as follows:\n$$\nF_Y(b) = P(Y \\leq b) = F(\\infty, b)\n$$\n\n\n### Discrete Case\nIn the case where $X$ and $Y$ are both discrete random variables, it is convenient to define the *joint probability mass function* of X and Y by\n\n$$\np(x,y) = P(X = x, Y = y)\n$$\n\nThe probability mass function of $X$ can be obtained from $p(x,y)$ by\n$$\np_X(x) = P(X = x) = \\sum_{y:p(x,y)>0} p(x,y)\n$$\nSimilarly, the probability mass function of $Y$ can be obtained from $p(x,y)$ by\n$$\np_Y(y) = P(Y = y) = \\sum_{x:p(x,y)>0} p(x,y)\n$$\n\n\n### Continuous Case\nWe say that $X$ and $Y$ are *jointly continuous* if there exists a function $f(x,y)$, defined for all real $x$ and $y$, having the property that for all sets of $A$ and $B$ of real numbers,\n$$\nP(X \\in A, Y \\in B) = \\int_B \\int_A f(x,y) \\, dx \\, dy\n$$\n\nThe function $f(x,y)$ is called the *joint probability density function* of $X$ and $Y$. The probability density function of $X$ can be obtained from a knowledge of $f(x,y)$ by following reasoning:\n$$\n\\begin{align*}\nP(X \\in A) &= P(X \\in A, Y \\in (-\\infty, \\infty)) \\\\\n&= \\int_{-\\infty}^{\\infty} \\int_A f(x,y) \\, dx \\, dy \\\\\n&= \\int_A f_X(x) \\, dx \\\\\n\\end{align*}\n$$\n\nwhere\n\n$$\nf_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dy\n$$\n\nis thus the probability density function of $X$ (Marginal density). Similarly, the probability density function of $Y$ can be obtained from a knowledge of $f(x,y)$ by\n$$\nf_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dx\n$$\n\nSince cumulative distribution function is defined as\n$$\nF(a,b) = P(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a \\int_{-\\infty}^b f(x,y) \\, dx \\, dy\n$$\n\ndifferentiation yields\n$$\n\\frac{\\partial^2}{\\partial a \\partial b} F(a,b) = f(a,b)\n$$\n\nThus, as in the single variable case, differentiating the probability distribution function gives the probability density function.\n\n### Expectation of one random variable for jointly distributed random variables\n\n#### In Discrete Case\n\nIn the discrete case, if $X$ and $Y$ are jointly distributed random variables, then the expected value of $X$ is given by\n$$\nE(X) = \\sum_{x_i} \\sum_{y_j} x_i p(x_i,y_j)\n$$\nand the expected value of $Y$ is given by\n$$\nE(Y) = \\sum_{x_i} \\sum_{y_j} y_j p(x_i,y_j)\n$$\n\n\n#### In Continuous Case\n\nThe expected value of $X$ is given by\n\n$$\nE(X) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x f(x,y) \\, dx \\, dy\n$$\n\n\nSimilarly, the expected value of $Y$ is given by\n$$\nE(Y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} y f(x,y) \\, dx \\, dy\n$$\n\n### Expectation of a Function of a Two Random Variables\n\nIf $X$ and $Y$ are random variables and $g$ is a function of two variables, then\n\n$$\n\\begin{align*}\nE(g(X,Y)) &= \\sum_{x_i} \\sum_{y_j} g(x_i,y_j) p(x_i,y_j) \\quad \\text{ in the discrete case} \\\\\n &= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x,y) f(x,y) \\, dx \\, dy \\quad \\text{ in the continuous case}\n\\end{align*}\n$$\n\n\n## Independent Random Variables\n\nThe random variables $X$ and $Y$ are said to be independent if, for all $a, b,$\n$$\nP(X \\leq a, Y \\leq b) = P(X \\leq a) P(Y \\leq b)\n$$\n\nIn terms of the joint cumulative distribution function, this means that\n$$\nF(a,b) = F_X(a) F_Y(b)\n$$\n\nWhen $X$ and $Y$ are discrete random variables, the independence condition can be expressed as\n$$\np(x,y) = p_X(x) p_Y(y)\n$$\n\nWhen $X$ and $Y$ are joint continuous, the independence reduces to\n$$\nf(x,y) = f_X(x) f_Y(y)\n$$\n\n### Proof for discrete case\nSuppose that the joint probability mass function $p(x,y)$, then\n\n$$\n\\begin{align*}\nP(X \\leq a, Y \\leq b) &= \\sum_{y \\leq b} \\sum_{x \\leq a} p(x,y) \\\\\n&= \\sum_{y \\leq b} \\sum_{x \\leq a} p_X(x) p_Y(y) \\\\\n&= \\left( \\sum_{x \\leq a} p_X(x) \\right) \\left( \\sum_{y \\leq b} p_Y(y) \\right) \\\\\n&= P(X \\leq a) P(Y \\leq b)\n\\end{align*}\n$$\n\nand so $X$ and $Y$ are independent.\n\n### Proof for continuous case\nSuppose that the joint probability density function $f(x,y)$, then\n$$\n\\begin{align*}\nP(X \\leq a, Y \\leq b) &= \\int_{-\\infty}^a \\int_{-\\infty}^b f(x,y) \\, dx \\, dy \\\\\n&= \\int_{-\\infty}^a \\int_{-\\infty}^b f_X(x) f_Y(y) \\, dx \\, dy \\\\\n&= \\left( \\int_{-\\infty}^a f_X(x) \\, dx \\right) \\left( \\int_{-\\infty}^b f_Y(y) \\, dy \\right) \\\\\n&= P(X \\leq a) P(Y \\leq b)\n\\end{align*}\n$$\n\n\n\n## Covariance and Variance of Sums of Random Variables\n\nThe covariance of any two random variables $X$ and $Y$, denoted by $Cov(X,Y)$, is defined by\n$$\nCov(X,Y) = E[(X - E(X))(Y - E(Y))] = E(XY) - E(X)E(Y)\n$$\nThe variance of a random variable $X$, denoted by $Var(X)$, is defined by\n$$\nVar(X) = E[(X - E(X))^2] = E(X^2) - (E(X))^2\n$$\n\n## Moment Generating Functions\n\n\n","srcMarkdownNoYaml":"\n\n# 1. Discrete Random Variables\n\nFor a discrete random variable $X$, we define the probability mass function $p(\\alpha)$ of $X$ by\n\n$$\np(\\alpha) = P(X = \\alpha)\n$$\n\nThe probability mass function $p(\\alpha)$ is positive for at most a countable number of values of $a$. That is, if $X$ must assume one of the values $x_1, x_2,\\dots ,$ then\n\n$$\np(x_i) \\geq 0 \\text{ for } i = 1, 2, \\dots\n$$\n\nand\n\n$$\n\\sum_{i=1}^{\\infty} p(x_i) = 1\n$$\n\nThe cumulative distribution function $F(x)$ can be expressed in terms of $p(\\alpha)$ by\n\n$$\nF(\\alpha) = P(X \\leq \\alpha) = \\sum_{x_i \\leq \\alpha} p(x_i)\n$$\n\n### Expectation of a Random Variable in Discrete Case\n\nIf $X$ is a discrete random variable having a probability mass function $p(x)$, then the expected value of $X$ is defined by\n\n$$\nE(X) = \\sum_{x_i} x_i p(x_i)\n$$\n\n\n\n\n## 1.1 Bernoulli Random Variable\n\nA Bernoulli random variable is a discrete random variable that takes the value 1 with probability $p$ and the value 0 with probability $1-p$. The probability mass function of a Bernoulli random variable $X$ is given by\n$$\np(x) = \\begin{cases}\n1-p & \\text{if } x = 0 \\\\\np & \\text{if } x = 1\n\\end{cases}\n$$\n\nThe expected value of a Bernoulli random variable is given by\n$$\nE(X) = 0 \\cdot (1-p) + 1 \\cdot p = p\n$$\n\nThe variance of a Bernoulli random variable is given by\n$$\nVar(X) = E(X^2) - (E(X))^2 = p - p^2 = p(1-p)\n$$\n\n## 1.2 Binomial Random Variable\n\nSuppose that $n$ independent trials, each of which results in a “success” with probability $p$ and in a “failure” with probability $1−p$, are to be performed. If $X$ represents the number of successes that occur in the $n$ trials, then $X$ is said to be a binomial random variable with parameters $n, p$. The probability mass function of a binomial random variable having parameters\n$(n, p)$ is given by\n\n$$\np(x) = \\binom{n}{x} p^x (1-p)^{n-x}, \\quad x = 0, 1, \\dots, n\n$$\n\nwhere $\\binom{n}{x} = \\frac{n!}{x!(n-x)!}$ is the binomial coefficient, which counts the number of ways to choose $x$ successes from $n$ trials.\n\n### Expectation of a Binomial Random Variable\n\nIf $X$ is a binomial random variable with parameters $n$ and $p$, then the expected value of $X$ is given by\n$$\nE(X) = np\n$$\n### Variance of a Binomial Random Variable\nIf $X$ is a binomial random variable with parameters $n$ and $p$, then the variance of $X$ is given by\n$$\nVar(X) = np(1-p)\n$$\n    \n\n## The Poisson Random Variable\n\nA random variable $X$ taking on one of the values $0, 1, 2, \\dots,$ is said to be a Poisson random variable with parameter $\\lambda$, if for some $\\lambda > 0$,\n\n$$\np(i) = P \\{ X = i \\} = e^{-\\lambda} \\frac{\\lambda^i}{i!}, \\quad i = 0, 1, \\ldots\n$$\n\n### Expectation of a Poisson Random Variable\n\nIf $X$ is a Poisson random variable with parameter $\\lambda$, then the expected value of $X$ is given by\n\n$$\nE(X) = \\sum_{i=0}^{\\infty} i e^{-\\lambda} \\frac{\\lambda^i}{i!}\n= e^{-\\lambda} \\sum_{i=1}^{\\infty} \\frac{\\lambda^i}{(i-1)!}\n= e^{-\\lambda} \\lambda \\sum_{i=0}^{\\infty} \\frac{\\lambda^i}{i!}\n= e^{-\\lambda} \\lambda e^{\\lambda}\n= \\lambda\n$$\n\nwhere we have used the identity $\\sum_{i=0}^{\\infty} \\frac{\\lambda^i}{i!} = e^{\\lambda}$.\n\n# 2. Continuous Random Variables\nThe function $f(x)$ is called the *probability density function* of the random variable $X$.\n$$\nP \\{X \\in B \\} = \\int_B f(x) dx \\tag{1}\n$$\n\nThe probability that $X$ will be in $B$ may be obtained by integrating the probability density function over the set $B$.\n\n$$\nP\\{X \\in (-\\infty, \\infty)\\} = \\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\n$$\n\n\nAll probability statements about $X$ can be answered in terms of $f(x)$. For instance, letting $B = [a, b]$, we obtain\n\n$$\nP\\{a \\leq X \\leq b \\} = \\int_a^b f(x) \\, dx \\tag{2}\n$$\n\nThe relationship between the cumulative distribution $F(\\cdot)$ and the probability density $f(\\cdot)$ is expressed by\n\n$$\nF(\\alpha) = P\\{X \\in (-\\infty, \\alpha]\\} = \\int_{-\\infty}^{\\alpha} f(x) \\, dx\n$$\n\nDifferentiating both sides of the preceding yields\n$$\n\\frac{d}{d\\alpha} F(\\alpha) = f(\\alpha)\n$$\n\nThat is, the density is the derivative of the cumulative distribution function. A somewhat more intuitive interpretation of the density function may be obtained from Equation (2) as\n\n$$\nP\\{\\alpha-\\frac{\\epsilon}{2} \\leq X \\leq \\alpha+\\frac{\\epsilon}{2} \\} = \\int_{\\alpha-\\frac{\\epsilon}{2}}^{a+\\frac{\\epsilon}{2}} f(x) \\, dx  \\approx \\epsilon f(x)\n$$\n\nwhen $\\epsilon$ is small. In other words, the probability that $X$ will be contained in an interval of length $\\epsilon$ around the point $\\alpha$ is approximately $\\epsilon f(a)$.\n\n\n### Expectation of a Random Variable in Continuous Case\nIf $X$ is a continuous random variable having a probability density function $f(x)$, then the expected value of $X$ is defined by\n$$\nE(X) = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n$$\n\n## 2.1 Exponential Random Variables\nA continuous random variable whose probability density function is given, for\nsome $\\lambda > 0$, by:\n$$\nf(x) = \\begin{cases}\n\\lambda e^{-\\lambda x} & x \\geq 0 \\\\\n0 & x < 0\n\\end{cases}\n$$\n\nis said to be an exponential random variable with parameter $\\lambda$, which is the mean of the distribution. The cumulative distribution function is given by\n\n$$\nF(\\alpha) =  \\int_0^\\alpha \\lambda e^{-\\lambda x} \\, dx, = 1-e^{-\\lambda \\alpha}  \\quad \\alpha \\geq 0\n$$\n\nNote that $F(\\infty) = \\int_0^\\infty \\lambda e^{-\\lambda x} \\, dx = 1$.\n\n### Expectation of an Exponential Random Variable\nIf $X$ is an exponential random variable with parameter $\\lambda$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_0^\\infty x \\lambda e^{-\\lambda x} \\, dx\n$$\n\nIntegration by parts ($dv = \\lambda e^{-\\lambda x}, u = x$) yields\n$$\nE(X) = \\left[ -\\frac{x}{\\lambda} e^{-\\lambda x} \\right]_0^\\infty + \\frac{1}{\\lambda} \\int_0^\\infty e^{-\\lambda x} \\, dx\n= 0 + \\frac{1}{\\lambda} \\cdot \\frac{1}{\\lambda} = \\frac{1}{\\lambda}\n$$\n\n\n## 2.2 Gamma Random Variables\n\nA continuous random variable whose density is given by:\n$$\nf(x) = \\begin{cases}\n\\frac{\\lambda e^{- \\lambda x} {(\\lambda x)}^{\\alpha-1}}{\\Gamma (\\alpha)} & x \\geq 0 \\\\\n0 & x < 0\n\\end{cases}\n$$\n\nfor some $\\lambda>0$ and $\\alpha>0$ is said to be a gamma random variable with parameters\n$\\alpha, \\lambda$. \n\nThe quantity $\\Gamma (\\alpha)$ is called the gamma function and is defined by\n\n$$\n\\Gamma (\\alpha) = \\int_0^\\infty e^{-x} x^{\\alpha-1} \\, dx = (\\alpha-1)!\n$$\n\n### Expectation of a Gamma Random Variable\nIf $X$ is a gamma random variable with parameters $\\alpha$ and $\\lambda$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_0^\\infty x \\frac{\\lambda e^{- \\lambda x} {(\\lambda x)}^{\\alpha-1}}{\\Gamma (\\alpha)} \\, dx\n= \\frac{1}{\\lambda} \\int_0^\\infty e^{-x} x^{\\alpha} \\, dx\n= \\frac{1}{\\lambda} \\cdot \\Gamma (\\alpha + 1)\n= \\frac{1}{\\lambda} \\cdot \\alpha \\Gamma (\\alpha)\n= \\frac{\\alpha}{\\lambda}\n$$\n\n\n## 2.3 Normal Random Variables\n\nWe say that $X$ is a normal random variable (or simply that $X$ is normally distributed) with parameters $\\mu$ and $\\sigma ^2$ if the density of X is given by\n\n$$\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\quad -\\infty < x < \\infty\n$$\n\nThis density function is a bell-shaped curve that is symmetric around $\\mu$.\n\nThe mean of the normal distribution is $\\mu$ and the variance is $\\sigma^2$. The cumulative distribution function is given by\n\n$$\nF_X(\\alpha) = P(X \\leq \\alpha) = \\int_{-\\infty}^ \\alpha \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n$$\n\n### Expectation of a Normal Random Variable\nIf $X$ is a normal random variable with parameters $\\mu$ and $\\sigma^2$, then the expected value of $X$ is given by\n$$\nE(X) = \\int_{-\\infty}^\\infty x \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n= \\mu \\int_{-\\infty}^\\infty \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-(x-\\mu)/ 2\\sigma^2} \\, dx\n= \\mu \\cdot 1\n= \\mu\n$$\n\n\n\n\n## Expectation of a Function of a Random Variable\n\n### In Discrete Case\nIf $X$ is a discrete random variable having a probability mass function $p(x)$, and $g(x)$ is a function of $x$, then the expected value of $g(X)$ is defined by\n$$\nE(g(X)) = \\sum_{x_i} g(x_i) p(x_i)\n$$\n### In Continuous Case\nIf $X$ is a continuous random variable having a probability density function $f(x)$, and $g(x)$ is a function of $x$, then the expected value of $g(X)$ is defined by\n$$\nE(g(X)) = \\int_{-\\infty}^{\\infty} g(x) f(x) \\, dx\n$$\n\n# Jointly Distributed Random Variables\n\nWe are often interested in probability statements concerning two or more random variables. To deal with such probabilities, we define, for any two random variables $X$ and $Y$, the joint cumulative probability distribution function of $X$ and $Y$ by\n\n$$\nF(a,b) = P(X \\leq a, Y \\leq b), \\quad -\\infty < a,b < \\infty\n$$\n\nThe cumulative distribution of $X$ can be obtained from the joint distribution of $X$ and $Y$ as follows:\n\n$$\n\\begin{align*}\nF_X(a) &= P(X \\leq a) \\\\\n& = P(X \\leq a, Y \\leq \\infty) \\\\\n& = F(a, \\infty) \\\\\n\\end{align*}\n$$\n\nSimilarly, the cumulative distribution of $Y$ can be obtained from the joint distribution of $X$ and $Y$ as follows:\n$$\nF_Y(b) = P(Y \\leq b) = F(\\infty, b)\n$$\n\n\n### Discrete Case\nIn the case where $X$ and $Y$ are both discrete random variables, it is convenient to define the *joint probability mass function* of X and Y by\n\n$$\np(x,y) = P(X = x, Y = y)\n$$\n\nThe probability mass function of $X$ can be obtained from $p(x,y)$ by\n$$\np_X(x) = P(X = x) = \\sum_{y:p(x,y)>0} p(x,y)\n$$\nSimilarly, the probability mass function of $Y$ can be obtained from $p(x,y)$ by\n$$\np_Y(y) = P(Y = y) = \\sum_{x:p(x,y)>0} p(x,y)\n$$\n\n\n### Continuous Case\nWe say that $X$ and $Y$ are *jointly continuous* if there exists a function $f(x,y)$, defined for all real $x$ and $y$, having the property that for all sets of $A$ and $B$ of real numbers,\n$$\nP(X \\in A, Y \\in B) = \\int_B \\int_A f(x,y) \\, dx \\, dy\n$$\n\nThe function $f(x,y)$ is called the *joint probability density function* of $X$ and $Y$. The probability density function of $X$ can be obtained from a knowledge of $f(x,y)$ by following reasoning:\n$$\n\\begin{align*}\nP(X \\in A) &= P(X \\in A, Y \\in (-\\infty, \\infty)) \\\\\n&= \\int_{-\\infty}^{\\infty} \\int_A f(x,y) \\, dx \\, dy \\\\\n&= \\int_A f_X(x) \\, dx \\\\\n\\end{align*}\n$$\n\nwhere\n\n$$\nf_X(x) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dy\n$$\n\nis thus the probability density function of $X$ (Marginal density). Similarly, the probability density function of $Y$ can be obtained from a knowledge of $f(x,y)$ by\n$$\nf_Y(y) = \\int_{-\\infty}^{\\infty} f(x,y) \\, dx\n$$\n\nSince cumulative distribution function is defined as\n$$\nF(a,b) = P(X \\leq a, Y \\leq b) = \\int_{-\\infty}^a \\int_{-\\infty}^b f(x,y) \\, dx \\, dy\n$$\n\ndifferentiation yields\n$$\n\\frac{\\partial^2}{\\partial a \\partial b} F(a,b) = f(a,b)\n$$\n\nThus, as in the single variable case, differentiating the probability distribution function gives the probability density function.\n\n### Expectation of one random variable for jointly distributed random variables\n\n#### In Discrete Case\n\nIn the discrete case, if $X$ and $Y$ are jointly distributed random variables, then the expected value of $X$ is given by\n$$\nE(X) = \\sum_{x_i} \\sum_{y_j} x_i p(x_i,y_j)\n$$\nand the expected value of $Y$ is given by\n$$\nE(Y) = \\sum_{x_i} \\sum_{y_j} y_j p(x_i,y_j)\n$$\n\n\n#### In Continuous Case\n\nThe expected value of $X$ is given by\n\n$$\nE(X) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} x f(x,y) \\, dx \\, dy\n$$\n\n\nSimilarly, the expected value of $Y$ is given by\n$$\nE(Y) = \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} y f(x,y) \\, dx \\, dy\n$$\n\n### Expectation of a Function of a Two Random Variables\n\nIf $X$ and $Y$ are random variables and $g$ is a function of two variables, then\n\n$$\n\\begin{align*}\nE(g(X,Y)) &= \\sum_{x_i} \\sum_{y_j} g(x_i,y_j) p(x_i,y_j) \\quad \\text{ in the discrete case} \\\\\n &= \\int_{-\\infty}^{\\infty} \\int_{-\\infty}^{\\infty} g(x,y) f(x,y) \\, dx \\, dy \\quad \\text{ in the continuous case}\n\\end{align*}\n$$\n\n\n## Independent Random Variables\n\nThe random variables $X$ and $Y$ are said to be independent if, for all $a, b,$\n$$\nP(X \\leq a, Y \\leq b) = P(X \\leq a) P(Y \\leq b)\n$$\n\nIn terms of the joint cumulative distribution function, this means that\n$$\nF(a,b) = F_X(a) F_Y(b)\n$$\n\nWhen $X$ and $Y$ are discrete random variables, the independence condition can be expressed as\n$$\np(x,y) = p_X(x) p_Y(y)\n$$\n\nWhen $X$ and $Y$ are joint continuous, the independence reduces to\n$$\nf(x,y) = f_X(x) f_Y(y)\n$$\n\n### Proof for discrete case\nSuppose that the joint probability mass function $p(x,y)$, then\n\n$$\n\\begin{align*}\nP(X \\leq a, Y \\leq b) &= \\sum_{y \\leq b} \\sum_{x \\leq a} p(x,y) \\\\\n&= \\sum_{y \\leq b} \\sum_{x \\leq a} p_X(x) p_Y(y) \\\\\n&= \\left( \\sum_{x \\leq a} p_X(x) \\right) \\left( \\sum_{y \\leq b} p_Y(y) \\right) \\\\\n&= P(X \\leq a) P(Y \\leq b)\n\\end{align*}\n$$\n\nand so $X$ and $Y$ are independent.\n\n### Proof for continuous case\nSuppose that the joint probability density function $f(x,y)$, then\n$$\n\\begin{align*}\nP(X \\leq a, Y \\leq b) &= \\int_{-\\infty}^a \\int_{-\\infty}^b f(x,y) \\, dx \\, dy \\\\\n&= \\int_{-\\infty}^a \\int_{-\\infty}^b f_X(x) f_Y(y) \\, dx \\, dy \\\\\n&= \\left( \\int_{-\\infty}^a f_X(x) \\, dx \\right) \\left( \\int_{-\\infty}^b f_Y(y) \\, dy \\right) \\\\\n&= P(X \\leq a) P(Y \\leq b)\n\\end{align*}\n$$\n\n\n\n## Covariance and Variance of Sums of Random Variables\n\nThe covariance of any two random variables $X$ and $Y$, denoted by $Cov(X,Y)$, is defined by\n$$\nCov(X,Y) = E[(X - E(X))(Y - E(Y))] = E(XY) - E(X)E(Y)\n$$\nThe variance of a random variable $X$, denoted by $Var(X)$, is defined by\n$$\nVar(X) = E[(X - E(X))^2] = E(X^2) - (E(X))^2\n$$\n\n## Moment Generating Functions\n\n\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"enable":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../../../styles.css"],"toc":true,"output-file":"distributions.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.29","linkcolor":"black","theme":"cosmo","title":"Random Variables","author":[{"name":"Mustafa Aslan","title":"PhD Student","affiliation":"Cardiff University, UK","email":"aslanm@cardiff.ac.uk"}],"description":"A quick notebook on distributions in statistics and machine learning.","date":"2025-04-23","categories":["talks"]},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}